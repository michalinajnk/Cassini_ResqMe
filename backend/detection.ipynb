{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3EppRNPqLFq",
        "outputId": "79cb07d9-52f0-4b26-f684-3227870714de"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (24.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.8.30)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.26.4)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from rasterio) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess"
      ],
      "metadata": {
        "id": "-YjdULVCpjJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "\n",
        "def load_tiff_band(tiff_path, band_index=1):\n",
        "    \"\"\"\n",
        "    Load a specific band from a multi-band TIFF file.\n",
        "\n",
        "    :param tiff_path: Path to the .tif file.\n",
        "    :param band_index: The band to extract (1-indexed).\n",
        "    :return: PyTorch tensor of the band data.\n",
        "    \"\"\"\n",
        "    # Open the TIFF file using rasterio\n",
        "    with rasterio.open(tiff_path) as dataset:\n",
        "        # Read the specific band (1-indexed in rasterio)\n",
        "        band_data = dataset.read(band_index)\n",
        "\n",
        "    # Normalize the band data to [0, 1] by dividing by the max value (65535 for UINT16)\n",
        "    band_data = band_data.astype(np.float32) / 65535.0  # Adjust normalization as needed\n",
        "\n",
        "    # Convert the band to a PyTorch tensor\n",
        "    band_tensor = torch.tensor(band_data, dtype=torch.float32)\n",
        "\n",
        "    # Add channel dimension to match [C, H, W] format (1 channel since it's a single band)\n",
        "    band_tensor = band_tensor.unsqueeze(0)\n",
        "\n",
        "    return band_tensor"
      ],
      "metadata": {
        "id": "OnxspC8WpiCi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "sht4ZWHS1t3Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "utiF3KQcoVc1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BinaryClassifierCNN(nn.Module):\n",
        "    def __init__(self, in_channels=1):  # Set in_channels=1 for single-band input\n",
        "        super(BinaryClassifierCNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "\n",
        "        # Adaptive Global Pooling to ensure output is fixed size\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # Fully connected layer (final layer)\n",
        "        self.fc = nn.Linear(128, 1)  # Output a single value for binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor before feeding it into fully connected layer\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(x)  # Sigmoid to get probability between 0 and 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "JShUa_Np1wYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Initialize the model\n",
        "model = BinaryClassifierCNN(in_channels=1)\n",
        "criterion = nn.BCELoss()  # Binary cross-entropy loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Move model to device (GPU if available)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "4Y2orMjKp-vk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "band_tensor1 = load_tiff_band('tir.tiff', band_index=1).to(device)\n",
        "band_tensor2 = load_tiff_band('tir2.tiff', band_index=1).to(device)\n",
        "\n",
        "# Simulating a binary label (0 or 1)\n",
        "label = torch.tensor([1, 0], dtype=torch.float32).unsqueeze(1).to(device)  # 1 for positive class, 0 for negative\n",
        "\n",
        "sample1 = band_tensor1.unsqueeze(0)  # Shape: [1, 1, H, W]\n",
        "sample2 = band_tensor2.unsqueeze(0)  # Shape: [1, 1, H, W]\n",
        "band_tensor = torch.cat([sample1, sample2], dim=0)  # Shape: [2, 1, H, W]\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    # Zero the gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(band_tensor)\n",
        "\n",
        "    # Calculate the loss\n",
        "    loss = criterion(outputs, label)\n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate accuracy\n",
        "    predicted_class = (outputs > 0.5).float()  # Predicted class is 1 if output > 0.5 else 0\n",
        "    correct = (predicted_class == label).sum().item()  # Compare with the true label\n",
        "    accuracy = correct / label.size(0)  # Accuracy as a fraction of correct predictions\n",
        "\n",
        "    # Print training progress and accuracy\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS3uGVaqqlkv",
        "outputId": "8a604521-f88d-4ecd-f543-7147480b5a9e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rasterio._env:CPLE_AppDefined in tir.tiff: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
            "WARNING:rasterio._env:CPLE_AppDefined in TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
            "WARNING:rasterio._env:CPLE_AppDefined in tir2.tiff: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
            "WARNING:rasterio._env:CPLE_AppDefined in TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6911, Accuracy: 0.5000\n",
            "Epoch [2/10], Loss: 0.6910, Accuracy: 0.5000\n",
            "Epoch [3/10], Loss: 0.6907, Accuracy: 0.5000\n",
            "Epoch [4/10], Loss: 0.6902, Accuracy: 0.5000\n",
            "Epoch [5/10], Loss: 0.6897, Accuracy: 0.5000\n",
            "Epoch [6/10], Loss: 0.6891, Accuracy: 0.5000\n",
            "Epoch [7/10], Loss: 0.6884, Accuracy: 0.5000\n",
            "Epoch [8/10], Loss: 0.6875, Accuracy: 0.5000\n",
            "Epoch [9/10], Loss: 0.6866, Accuracy: 0.5000\n",
            "Epoch [10/10], Loss: 0.6854, Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict"
      ],
      "metadata": {
        "id": "QxAbi6AJ1yGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Switch model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Load a new TIFF image for inference\n",
        "tiff_path = 'tir2.tiff'\n",
        "band_tensor = load_tiff_band(tiff_path, band_index=1).to(device)\n",
        "\n",
        "# Add batch dimension [B, C, H, W]\n",
        "band_tensor = band_tensor.unsqueeze(0)\n",
        "\n",
        "# Make a prediction (no gradient calculation needed)\n",
        "with torch.no_grad():\n",
        "    output = model(band_tensor)\n",
        "    predicted_class = (output > 0.5).float()  # Threshold at 0.5 to decide between class 0 and 1\n",
        "\n",
        "print(f\"Predicted class: {predicted_class.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_9q0umsqu3r",
        "outputId": "c461c5df-e49d-4f80-9877-416e7ffcfd46"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:rasterio._env:CPLE_AppDefined in tir2.tiff: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
            "WARNING:rasterio._env:CPLE_AppDefined in TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 0.0\n"
          ]
        }
      ]
    }
  ]
}